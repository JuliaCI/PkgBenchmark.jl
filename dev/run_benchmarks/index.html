<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Running a benchmark suite · PkgBenchmark.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">PkgBenchmark.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../define_benchmarks/">Defining a benchmark suite</a></li><li class="is-active"><a class="tocitem" href>Running a benchmark suite</a><ul class="internal"><li><a class="tocitem" href="#More-advanced-customization-1"><span>More advanced customization</span></a></li><li><a class="tocitem" href="#CI-Integration-1"><span>CI Integration</span></a></li></ul></li><li><a class="tocitem" href="../comparing_commits/">Comparing commits</a></li><li><a class="tocitem" href="../export_markdown/">Export to markdown</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Running a benchmark suite</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Running a benchmark suite</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaCI/PkgBenchmark.jl/blob/master/docs/src/run_benchmarks.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Running-a-benchmark-suite-1"><a class="docs-heading-anchor" href="#Running-a-benchmark-suite-1">Running a benchmark suite</a><a class="docs-heading-anchor-permalink" href="#Running-a-benchmark-suite-1" title="Permalink"></a></h1><p>Use <code>benchmarkpkg</code> to run benchmarks defined in a suite as defined in the previous section.</p><article class="docstring"><header><a class="docstring-binding" id="PkgBenchmark.benchmarkpkg" href="#PkgBenchmark.benchmarkpkg"><code>PkgBenchmark.benchmarkpkg</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">benchmarkpkg(pkg, [target]::Union{String, BenchmarkConfig}; kwargs...)</code></pre><p>Run a benchmark on the package <code>pkg</code> using the <a href="#PkgBenchmark.BenchmarkConfig"><code>BenchmarkConfig</code></a> or git identifier <code>target</code>. Examples of git identifiers are commit shas, branch names, or e.g. <code>&quot;HEAD~1&quot;</code>. Return a <a href="#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a>.</p><p>The argument <code>pkg</code> can be the module of a package, a package name, or the path to the package&#39;s root directory.</p><p><strong>Keyword arguments</strong>:</p><ul><li><code>script</code> - The script with the benchmarks, if not given, defaults to <code>benchmark/benchmarks.jl</code> in the package folder.</li><li><code>postprocess</code> - A function to post-process results. Will be passed the <code>BenchmarkGroup</code>, which it can modify, or return a new one.</li><li><code>resultfile</code> - If set, saves the output to <code>resultfile</code></li><li><code>retune</code> - Force a re-tune, saving the new tuning to the tune file.</li><li><code>verbose::Bool = true</code> - Print currently running benchmark.</li><li><code>logger_factory</code> - Specify the logger used during benchmark.  It is a callable object (typically a type) with no argument that creates a logger.  It must exist as a constant in some package (e.g., an anonymous function does not work).</li><li><code>progressoptions</code> - Deprecated.</li></ul><p>The result can be used by functions such as <a href="../comparing_commits/#BenchmarkTools.judge"><code>judge</code></a>. If you choose to, you can save the results manually using <a href="#PkgBenchmark.writeresults"><code>writeresults</code></a> where <code>results</code> is the return value of this function. It can be read back with <a href="#PkgBenchmark.readresults"><code>readresults</code></a>.</p><p><strong>Example invocations:</strong></p><pre><code class="language-julia">using PkgBenchmark

import MyPkg
benchmarkpkg(MyPkg) # run the benchmarks at the current state of the repository
benchmarkpkg(MyPkg, &quot;my-feature&quot;) # run the benchmarks for a particular branch/commit/tag
benchmarkpkg(MyPkg, &quot;my-feature&quot;; script=&quot;/home/me/mycustombenchmark.jl&quot;)
benchmarkpkg(MyPkg, BenchmarkConfig(id = &quot;my-feature&quot;,
                                            env = Dict(&quot;JULIA_NUM_THREADS&quot; =&gt; 4),
                                            juliacmd = `julia -O3`))
benchmarkpkg(MyPkg,  # Run the benchmarks and divide the (median of) results by 1000
    postprocess=(results)-&gt;(results[&quot;g&quot;] = median(results[&quot;g&quot;])/1_000)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/PkgBenchmark.jl/blob/6aab4956fbdf7e79a57cda260a2175bf5e13252a/src/runbenchmark.jl#L1-L41">source</a></section></article><p>The results of a benchmark is returned as a <code>BenchmarkResults</code>:</p><article class="docstring"><header><a class="docstring-binding" id="PkgBenchmark.BenchmarkResults" href="#PkgBenchmark.BenchmarkResults"><code>PkgBenchmark.BenchmarkResults</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Stores the results from running the benchmarks on a package.</p><p>The following (unexported) methods are defined on a <code>BenchmarkResults</code> (written below as <code>results</code>):</p><ul><li><code>name(results)::String</code> - The commit of the package benchmarked</li><li><code>commit(results)::String</code> - The commit of the package benchmarked. If the package repository was dirty, the string <code>&quot;dirty&quot;</code> is returned.</li><li><code>juliacommit(results)::String</code> - The commit of the Julia executable that ran the benchmarks</li><li><code>benchmarkgroup(results)::BenchmarkGroup</code> - a <a href="https://github.com/JuliaCI/BenchmarkTools.jl/blob/master/doc/manual.md#the-benchmarkgroup-type"><code>BenchmarkGroup</code></a>  contaning the results of the benchmark.</li><li><code>date(results)::DateTime</code> - The time when the benchmarks were executed</li><li><code>benchmarkconfig(results)::BenchmarkConfig</code> - The <a href="#PkgBenchmark.BenchmarkConfig"><code>BenchmarkConfig</code></a> used for the benchmarks.</li></ul><p><code>BenchmarkResults</code> can be exported to markdown using the function <a href="../export_markdown/#PkgBenchmark.export_markdown"><code>export_markdown</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/PkgBenchmark.jl/blob/6aab4956fbdf7e79a57cda260a2175bf5e13252a/src/benchmarkresults.jl#L1-L15">source</a></section></article><h2 id="More-advanced-customization-1"><a class="docs-heading-anchor" href="#More-advanced-customization-1">More advanced customization</a><a class="docs-heading-anchor-permalink" href="#More-advanced-customization-1" title="Permalink"></a></h2><p>Instead of passing a commit, branch etc. as a <code>String</code> to <code>benchmarkpkg</code>, a <a href="#PkgBenchmark.BenchmarkConfig"><code>BenchmarkConfig</code></a> can be passed</p><article class="docstring"><header><a class="docstring-binding" id="PkgBenchmark.BenchmarkConfig" href="#PkgBenchmark.BenchmarkConfig"><code>PkgBenchmark.BenchmarkConfig</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">BenchmarkConfig(;id::Union{String, Nothing} = nothing,
                 juliacmd::Cmd = `joinpath(Sys.BINDIR, Base.julia_exename())`,
                 env::Dict{String, Any} = Dict{String, Any}())</code></pre><p>A <code>BenchmarkConfig</code> contains the configuration for the benchmarks to be executed by <a href="#PkgBenchmark.benchmarkpkg"><code>benchmarkpkg</code></a>.</p><p>This includes the following:</p><ul><li>The commit of the package the benchmarks are run on.</li><li>What julia command should be run, i.e. the path to the Julia executable and</li></ul><p>the command flags used (e.g. optimization level with <code>-O</code>).</p><ul><li>Custom environment variables (e.g. <code>JULIA_NUM_THREADS</code>).</li></ul><p>The constructor takes the following keyword arguments:</p><ul><li><code>id</code> - A git identifier like a commit, branch, tag, &quot;HEAD&quot;, &quot;HEAD~1&quot; etc.        If <code>id == nothing</code> then benchmark will be done on the current state        of the repo (even if it is dirty).</li><li><code>juliacmd</code> - Used to execute the benchmarks, defaults to the julia executable              that the Pkgbenchmark-functions are called from. Can also include command flags.</li><li><code>env</code> - Contains custom environment variables that will be active when the         benchmarks are run.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia">julia&gt; using Pkgbenchmark

julia&gt; BenchmarkConfig(id = &quot;performance_improvements&quot;,
                       juliacmd = `julia -O3`,
                       env = Dict(&quot;JULIA_NUM_THREADS&quot; =&gt; 4))
BenchmarkConfig:
    id: performance_improvements
    juliacmd: `julia -O3`
    env: JULIA_NUM_THREADS =&gt; 4</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/PkgBenchmark.jl/blob/6aab4956fbdf7e79a57cda260a2175bf5e13252a/src/benchmarkconfig.jl#L7-L43">source</a></section></article><p>This object contains the package commit, julia command, and what environment variables will be used when benchmarking. The default values can be seen by using the default constructor</p><pre><code class="language-julia-repl">julia&gt; BenchmarkConfig()
BenchmarkConfig:
    id: nothing
    juliacmd: `/home/user/julia/julia`
    env:</code></pre><p>The <code>id</code> is a commit, branch etc as described in the previous section. An <code>id</code> with value <code>nothing</code> means that the current state of the package will be benchmarked. The default value of <code>juliacmd</code> is <code>joinpath(Sys.BINDIR, Base.julia_exename()</code> which is the command to run the julia executable without any command line arguments.</p><p>To instead benchmark the branch <code>PR</code>, using the julia command <code>julia -O3</code> with the environment variable <code>JULIA_NUM_THREADS</code> set to <code>4</code>, the config would be created as</p><pre><code class="language-julia-repl">julia&gt; config = BenchmarkConfig(id = &quot;PR&quot;,
                                juliacmd = `julia -O3`,
                                env = Dict(&quot;JULIA_NUM_THREADS&quot; =&gt; 4))
BenchmarkConfig:
    id: &quot;PR&quot;
    juliacmd: `julia -O3`
    env: JULIA_NUM_THREADS =&gt; 4</code></pre><p>To benchmark the package with the config, call <a href="#PkgBenchmark.benchmarkpkg"><code>benchmarkpkg</code></a> as e.g.</p><pre><code class="language-julia">benchmarkpkg(&quot;Tensors&quot;, config)</code></pre><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>The <code>id</code> keyword to the <code>BenchmarkConfig</code> does not have to be a branch, it can be most things that git can understand, for example a commit id or a tag.</p></div></div><p>Benchmarks can be saved and read using <code>writeresults</code> and `<code>readresults</code> respectively:</p><article class="docstring"><header><a class="docstring-binding" id="PkgBenchmark.readresults" href="#PkgBenchmark.readresults"><code>PkgBenchmark.readresults</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">readresults(file::String)</code></pre><p>Reads the <a href="#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a> stored in <code>file</code> (given as a path).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/PkgBenchmark.jl/blob/6aab4956fbdf7e79a57cda260a2175bf5e13252a/src/benchmarkresults.jl#L69-L73">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="PkgBenchmark.writeresults" href="#PkgBenchmark.writeresults"><code>PkgBenchmark.writeresults</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">writeresults(file::String, results::BenchmarkResults)</code></pre><p>Writes the <a href="#PkgBenchmark.BenchmarkResults"><code>BenchmarkResults</code></a> to <code>file</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaCI/PkgBenchmark.jl/blob/6aab4956fbdf7e79a57cda260a2175bf5e13252a/src/benchmarkresults.jl#L48-L52">source</a></section></article><h2 id="CI-Integration-1"><a class="docs-heading-anchor" href="#CI-Integration-1">CI Integration</a><a class="docs-heading-anchor-permalink" href="#CI-Integration-1" title="Permalink"></a></h2><p>Tracking changes in performance throughout the development of a package can be automated as part of package CI.</p><p><a href="https://github.com/tkf/BenchmarkCI.jl">BenchmarkCI.jl</a> provides a convenient way to run a PkgBenchmark suite as part of a package&#39;s CI actions.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../define_benchmarks/">« Defining a benchmark suite</a><a class="docs-footer-nextpage" href="../comparing_commits/">Comparing commits »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 8 June 2023 11:29">Thursday 8 June 2023</span>. Using Julia version 1.9.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
